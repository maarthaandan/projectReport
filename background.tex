\chapter{Background Information}
\section{Image Super Resolution}
Images are very important sources of information. Images have applications in a wide variety of fields. Image capturing equipments have not been able to achieve the capacity to produce high quality images under all circumstances. Recent upsurge in the popularity of image based applications has necessitated the need for content quality. Image Super Resolution (ISR) aims to increase the size of an image while keeping the accompanying loss in quality to minimum.



\section{Generative Adversarial Network}
Generative Adversarial Networks (GANs) are a class of machine learning algorithms consisting of two neural networks contesting with each other in a zero-sum game framework. GANs were introduced by Ian Goodfellow in his paper “Generative Adversarial Nets” published in 2014. The concept is that given enough computing power, two neural networks can contest with each other and learn through plain old backpropagation. One network generates while the other evaluates. The generative network learns to map data to a particular data distribution of interest, while the discriminative network discriminates between instances from the true data distribution and candidates produced by the generator. The generative network's training objective is to increase the error rate of the discriminative network .   
The training procedure needs a dataset of high resolution images. The discriminator is trained by giving images until it reaches a certain level of accuracy. The generator is given as input low resolution images. It produces super resolved versions of its input. The samples generated by the generator are evaluated by the discriminator. Backpropagation is applied to both the networks, where the the discriminator becomes more skilled at flagging the images produced by the generator as fake (due to it not being as good as the original high resolution image) whereas generator becomes more skilled at producing super resolved images that are as close to reality as possible. Thus, this method can be used to generate images that look authentic to human observers, having many realistic characteristics.  It is the first framework capable of inferring photo realistic natural images for 4X upscaling factors. 
The usual convolutional neural networks tries to improve its performance by minimizing the Mean Squared Error Loss(MSE Loss). The MSE Loss is a pixel concept and overly relies on the pixel space. Another loss function that captures the perceptual properties of the image is the VGG Loss Network. As the name suggests, it is a neural network that it used to compute the loss, which is to be minimized. The VGG network is a pre trained network that extracts the features from an image. It takes in the features of the super resolved image of the generator and compares it with the features extracted from the original high resolution image. The use of VGG loss pushes the GAN to produce images of photo-realistic quality.

The presented method and algorithm was first  presented in a paper by Christian Ledig, Lucas Theis, Ferenc Huszár and others. It was presented to the world at the Conference on Computer Vision and Pattern Recognition on July 21 2017. The paper presented the method for producing photo realistic super resolved images using Generative Adversarial Networks. 